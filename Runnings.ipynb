{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Runnings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuj8pA5yfdDE",
        "outputId": "a620316d-6abb-4509-e834-1275e3af5e4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soi9eJYkkZa7",
        "outputId": "aa446815-9de4-437c-ad33-60a01a879a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd drive/MyDrive\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUcYfWVoYOXN"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "from datetime import datetime\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.transforms import Resize, functional\n",
        "\n",
        "import PIL\n",
        "import random\n",
        "import torchvision\n",
        "\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFOpQQUIYiWM"
      },
      "source": [
        "# hacks for time-saving\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "keTR12CKjCm4",
        "outputId": "7a711f35-0f83-4878-eb0e-79a1661f0691"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftEk3z1MhK4F",
        "outputId": "d4ede8a1-8215-431a-95bb-89baf00448df"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 15 08:45:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    32W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqcha-jmncfh"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFT2L4tPd2hx"
      },
      "source": [
        "def get_train_test_paths(test_ratio: float = 0.2):\n",
        "    # extract the data from the dataset folder\n",
        "    files = [file_name for file_name in\n",
        "             Path(os.getcwd() + os.sep + 'Water Bodies Dataset' + os.sep + 'Images').rglob(\"*.jpg\")]\n",
        "    # randomize the order of the data\n",
        "    random.shuffle(files)\n",
        "    # separate test and train files\n",
        "    first_train = int(test_ratio * len(files))\n",
        "    test_path = files[:first_train]\n",
        "    train_path = files[first_train:]\n",
        "    return train_path, test_path\n",
        "\n",
        "\n",
        "def get_mask_path(file_path):\n",
        "    # gets source image path, returns mask path\n",
        "    file_path = str(file_path).replace('Images', 'Masks')\n",
        "    return file_path\n",
        "\n",
        "\n",
        "class WaterDataset(Dataset):\n",
        "    def __init__(self, path_list, transform_source=None, transform_both=None):\n",
        "        self.sources = path_list\n",
        "        self.transform_source = transform_source\n",
        "        self.transform_both = transform_both\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sources)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.sources[index]\n",
        "        source = functional.to_tensor(PIL.Image.open(img_path))\n",
        "        label = functional.to_tensor(PIL.Image.open(get_mask_path(img_path)).convert('L'))\n",
        "\n",
        "        if self.transform_source:\n",
        "            source = self.transform_source(source)\n",
        "        if self.transform_both:\n",
        "            source = self.transform_both(source)\n",
        "            label = self.transform_both(label)\n",
        "            label = (label < 0.5).float()\n",
        "\n",
        "            assert len(label.unique()) <= 2, \"threshold didn't work\"\n",
        "\n",
        "        return source, label\n",
        "\n",
        "\n",
        "def get_train_test_loaders(batch_size, length):\n",
        "    train_path, test_path = get_train_test_paths()\n",
        "    train_loader = DataLoader(dataset=WaterDataset(train_path,\n",
        "                                                   transform_both=torchvision.transforms.Resize((length, length))),\n",
        "                              batch_size=batch_size,\n",
        "                              pin_memory=True,\n",
        "                              num_workers=2,\n",
        "                              shuffle=True)\n",
        "    test_loader = DataLoader(dataset=WaterDataset(test_path,\n",
        "                                                  transform_both=torchvision.transforms.Resize((length, length))),\n",
        "                             batch_size=batch_size,\n",
        "                             pin_memory=True,\n",
        "                             num_workers=2)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWCYst_PeX88"
      },
      "source": [
        "class Hidden1(nn.Module):\n",
        "    # define the model\n",
        "    def __init__(self, length, hidden_size, activation):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.length = length\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(length**2 * 3, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, length**2 * 2)  # 2 for each class\n",
        "\n",
        "    # set activation functions for the layers\n",
        "    def forward(self, x):\n",
        "        x = self.flat(x)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = x.reshape(x.size(0) * self.length**2, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Hidden2(nn.Module):\n",
        "    # define the model\n",
        "    def __init__(self, length, hidden_size, activation):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.length = length\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(length**2 * 3, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, length**2 * 2)  # 2 for each class\n",
        "\n",
        "    # set activation functions for the layers\n",
        "    def forward(self, x):\n",
        "        x = self.flat(x)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = x.reshape(x.size(0) * self.length**2, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv1(nn.Module):\n",
        "    # define the model\n",
        "    def __init__(self, length, hidden_size, activation, kernel_size: int = 3):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.length = length\n",
        "        self.kernel_size = kernel_size  # expected odd kernel_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 3, self.kernel_size, padding=int((self.kernel_size - 1) / 2))\n",
        "        self.fc1 = nn.Linear(length**2 * 3, self.hidden_size)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.fc3 = nn.Linear(self.hidden_size, length**2 * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.conv1(x))\n",
        "        x = f.max_pool2d(x, kernel_size=self.kernel_size, stride=1, padding=int((self.kernel_size - 1) / 2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = x.reshape(x.size(0) * self.length**2, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv2(nn.Module):\n",
        "    # define the model\n",
        "    def __init__(self, length, hidden_size, activation, kernel_size: int = 3):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.length = length\n",
        "        self.kernel_size = kernel_size  # expected odd kernel_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 3, self.kernel_size, padding=int((self.kernel_size - 1) / 2))\n",
        "        self.conv2 = nn.Conv2d(3, 3, self.kernel_size, padding=int((self.kernel_size - 1) / 2))\n",
        "        self.fc1 = nn.Linear(length**2 * 3, self.hidden_size)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.fc3 = nn.Linear(self.hidden_size, length**2 * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.conv1(x))\n",
        "        x = f.max_pool2d(x, kernel_size=self.kernel_size, stride=1, padding=int((self.kernel_size - 1) / 2))\n",
        "        x = self.activation(self.conv2(x))\n",
        "        x = f.max_pool2d(x, kernel_size=self.kernel_size, stride=1, padding=int((self.kernel_size - 1) / 2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = x.reshape(x.size(0) * self.length**2, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv3(nn.Module):\n",
        "    # define the model\n",
        "    def __init__(self, length, hidden_size, activation, kernel_size: int = 3):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.length = length\n",
        "        self.kernel_size = kernel_size  # expected odd kernel_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 3, self.kernel_size, padding=int((self.kernel_size - 1) / 2))\n",
        "        self.conv2 = nn.Conv2d(3, 3, self.kernel_size, padding=int((self.kernel_size - 1) / 2))\n",
        "        self.conv3 = nn.Conv2d(3, 3, self.kernel_size, padding=int((self.kernel_size - 1) / 2))\n",
        "        self.fc1 = nn.Linear(length**2 * 3, self.hidden_size)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.fc3 = nn.Linear(self.hidden_size, length**2 * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.conv1(x))\n",
        "        x = f.max_pool2d(x, kernel_size=self.kernel_size, stride=1, padding=int((self.kernel_size - 1) / 2))\n",
        "        x = self.activation(self.conv2(x))\n",
        "        x = f.max_pool2d(x, kernel_size=self.kernel_size, stride=1, padding=int((self.kernel_size - 1) / 2))\n",
        "        x = self.activation(self.conv3(x))\n",
        "        x = f.max_pool2d(x, kernel_size=self.kernel_size, stride=1, padding=int((self.kernel_size - 1) / 2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = x.reshape(x.size(0) * self.length**2, 2)\n",
        "        return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYk4rGGDeafp"
      },
      "source": [
        "def save_prediction(prediction, index, name):\n",
        "    # convert two-valued pixels to single-max-value\n",
        "    prediction = torch.argmax(prediction, dim=1)\n",
        "    # reshape the flattened prediction to a matrix\n",
        "    prediction = prediction.reshape(100, 100)\n",
        "    # get original size\n",
        "    source_path = f'{os.getcwd()}{os.sep}Water Bodies Dataset{os.sep}Images{os.sep}water_body_{index}.jpg'\n",
        "    width, height = cv2.imread(source_path).shape\n",
        "    # resize prediction to original source size\n",
        "    prediction = Resize(prediction, size=(width, height))\n",
        "    prediction_path = f'{os.getcwd()}{os.sep}Deep Images{os.sep}{name}_{index}.jpg'\n",
        "    # save the prediction\n",
        "    save_image(prediction, prediction_path)\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    \"\"\"https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/6\"\"\"\n",
        "    pp = 0\n",
        "    for p in list(model.parameters()):\n",
        "        nn = 1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn * s\n",
        "        pp += nn\n",
        "    return pp\n",
        "\n",
        "\n",
        "def get_img_index(path):\n",
        "    index = str(path).split('_')[-1].split('.')[0]\n",
        "    return index\n",
        "\n",
        "\n",
        "def fit_model(model, model_parameters, loss_function, optimizer, batch_size, image_normalized_length, num_of_epochs):\n",
        "    # retrieve train and test files\n",
        "    train_loader, test_loader = get_train_test_loaders(batch_size, image_normalized_length)\n",
        "    # if GPU is available, prepare it for heavy calculations\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # assign the model\n",
        "    model = model(*model_parameters).to(device)\n",
        "    # assign the loss function\n",
        "    criterion = loss_function()\n",
        "    # set an optimizer\n",
        "    optimizer = optimizer(model.parameters(), lr=3e-4)\n",
        "    for epoch in range(1, num_of_epochs + 1):\n",
        "        # MODEL TRAINING\n",
        "        model.train()\n",
        "        # start counting epoch duration\n",
        "        epoch_start = datetime.now()\n",
        "        # initiate epoch loss\n",
        "        epoch_loss = 0\n",
        "        # iterate through all data pairs\n",
        "        for image, mask in tqdm(train_loader):\n",
        "            # convert input pixel to tensor\n",
        "            x = image.float().to(device)\n",
        "            # convert target to tensor\n",
        "            tag = mask.flatten().long().to(device)\n",
        "            # reset all gradients\n",
        "            optimizer.zero_grad()\n",
        "            # save current prediction\n",
        "            prediction = model(x)\n",
        "            # activate loss function, calculate loss\n",
        "            loss = criterion(prediction, tag)\n",
        "            # back propagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # update epoch loss\n",
        "            epoch_loss += loss.item()\n",
        "        # stop counting epoch duration\n",
        "        epoch_end = datetime.now()\n",
        "        epoch_seconds = (epoch_end - epoch_start).total_seconds()\n",
        "        # MODEL EVALUATION\n",
        "        model.eval()\n",
        "        # collect predicted results and real results\n",
        "        total_predicted_positive, total_true_positive, total_false_negative, \\\n",
        "        total_true_prediction, total_false_prediction = 0, 0, 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in tqdm(test_loader):\n",
        "                x = x.to(device)\n",
        "                y = y.flatten().to(device)\n",
        "                probabilities = model(x)\n",
        "                prediction = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "                predicted_positive = (prediction == 1).sum().item()\n",
        "                true_positive = ((prediction == 1) & (y == 1)).sum().item()\n",
        "                false_negative = ((prediction == 0) & (y == 1)).sum().item()\n",
        "\n",
        "                total_predicted_positive += predicted_positive\n",
        "                total_true_positive += true_positive\n",
        "                total_false_negative += false_negative\n",
        "                total_true_prediction += (prediction == y).sum().item()\n",
        "                total_false_prediction += (prediction != y).sum().item()\n",
        "        # calculate accuracy and f1 score\n",
        "        recall = total_true_positive / (total_true_positive + total_false_negative)\n",
        "        precision = total_true_positive / total_predicted_positive\n",
        "        f1 = (2 * precision * recall) / (precision + recall)\n",
        "        accuracy = total_true_prediction / (total_true_prediction + total_false_prediction)\n",
        "        # append results to csv file\n",
        "        df = pd.DataFrame({'Model Name': [model.__class__.__name__],\n",
        "                           'Iteration': [epoch],\n",
        "                           'Input Image Length': [image_normalized_length],\n",
        "                           'Hidden Layer Size': [hidden_layer_size],\n",
        "                           'Batch Size': [batch_size],\n",
        "                           'Activation Function': [str(model_parameters[2].__name__)],\n",
        "                           'Optimizer': [str(type(optimizer))],\n",
        "                           'Loss Function': [str(loss_function)],\n",
        "                           'Loss': [epoch_loss],\n",
        "                           'Recall': [recall],\n",
        "                           'Precision': [precision],\n",
        "                           'F1': [f1],\n",
        "                           'Accuracy': [accuracy],\n",
        "                           'Iteration Training Seconds': [epoch_seconds]})\n",
        "        df.to_csv('Water_Bodies_Results.csv', index=False, mode='a', header=False)\n",
        "        print(df)\n",
        "\n",
        "    ### SAVE A PREDICTION ###\n",
        "    # with torch.no_grad():\n",
        "    #     for i, image, mask in enumerate(test_loader):\n",
        "    #         name = ''\n",
        "    #         x = image.float().to(device)\n",
        "    #         tag = mask.flatten().long().to(device)\n",
        "    #         prediction = model(x)\n",
        "    #         file_name, _ = test_loader.dataset.samples[i]\n",
        "    #         file_index = get_img_index(file_name)\n",
        "    #         save_prediction(prediction, file_index, name)\n",
        "\n",
        "    # clean memory of current model on exit\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    models = (Hidden1,)\n",
        "    activation_funcs = (f.relu, f.leaky_relu)\n",
        "    hidden_layer_sizes = (4000, 3000, 2000)\n",
        "\n",
        "    optimizer = optim.Adam\n",
        "    loss_func = nn.CrossEntropyLoss\n",
        "    image_normalized_length = 100\n",
        "    batch_size = 16\n",
        "    num_of_epochs = 10\n",
        "    kernel_size = 3\n",
        "\n",
        "    # train models with varying hyperparameters\n",
        "    for model in models:\n",
        "        for activation_func in activation_funcs:\n",
        "            for hidden_layer_size in hidden_layer_sizes:\n",
        "                model_parameters = (image_normalized_length, hidden_layer_size, activation_func)\n",
        "                fit_model(model, model_parameters, loss_func, optimizer,\n",
        "                          batch_size, image_normalized_length, num_of_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIRnvFBRg5R1"
      },
      "source": [
        "### WIPE RESULTS FILE ###\n",
        "# df = pd.DataFrame({'Model Name': [],\n",
        "#                    'Iteration': [],\n",
        "#                    'Input Image Length': [],\n",
        "#                    'Hidden Layer Size': [],\n",
        "#                    'Batch Size': [],\n",
        "#                    'Activation Function': [],\n",
        "#                    'Optimizer': [],\n",
        "#                    'Loss Function': [],\n",
        "#                    'Loss': [],\n",
        "#                    'Recall': [],\n",
        "#                    'Precision': [],\n",
        "#                    'F1': [],\n",
        "#                    'Accuracy': [],\n",
        "#                    'Iteration Training Seconds': []})\n",
        "# df.to_csv('Water_Bodies_Results.csv', index=False, header=True)"
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}